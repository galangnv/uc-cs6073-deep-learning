{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lec 32: GANs II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "1. The GAN model covered in the lecture used fully connected layers in discriminator and generator. In this exercise, use at least two convolutional layers in discriminator and two transposed convolutions in the generator. Train the model on MNIST data and tweak the hyperparameters as needed to do training effectively.\n",
    "2. Compare the results of your new GAN generator with the one in the lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import helper files\n",
    "from helpers.helper_utils import set_all_seeds\n",
    "from helpers.helper_data import get_dataloaders_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 128\n",
    "GENERATOR_LEARNING_RATE = 0.0002\n",
    "DISCRIMINATOR_LEARNING_RATE = 0.0002\n",
    "\n",
    "# Other settings\n",
    "DEVICE = torch.device(f'cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "RANDOM_SEED = 42\n",
    "IMAGE_HEIGHT = 28\n",
    "IMAGE_WIDTH = 28\n",
    "IMAGE_CHANNELS = 1\n",
    "\n",
    "set_all_seeds(RANDOM_SEED)\n",
    "print(f'Device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running on Colab, uncomment this code\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# SAVED_DATA_PATH = 'drive/MyDrive/saved_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_dataloaders_mnist(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    train_transforms=custom_transforms\n",
    ")\n",
    "\n",
    "# Verify dataset\n",
    "for images, labels in train_loader:\n",
    "    print(f'Image batch dimensions: {images.size()}')\n",
    "    print(f'Image label dimensions: {labels.size()}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.axis('off')\n",
    "plt.title('Training Images')\n",
    "plt.imshow(\n",
    "    np.transpose(\n",
    "        torchvision.utils.make_grid(\n",
    "            images[:64],\n",
    "            padding=2,\n",
    "            normalize=True\n",
    "        ),\n",
    "        (1, 2, 0)\n",
    "    )\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Model (from lecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim=100,\n",
    "        image_height=28,\n",
    "        image_width=28,\n",
    "        color_channels=1\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_height = image_height\n",
    "        self.image_width = image_width\n",
    "        self.color_channels = color_channels\n",
    "\n",
    "        self.generator = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "\n",
    "            nn.Linear(128, image_height * image_width * color_channels),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(image_height * image_width * color_channels, 128),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            \n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "    \n",
    "    def generator_forward(self, z):\n",
    "        z = torch.flatten(z, start_dim=1)\n",
    "        img = self.generator(z)\n",
    "        img = img.view(\n",
    "            z.size(0),\n",
    "            self.color_channels,\n",
    "            self.image_height,\n",
    "            self.image_width\n",
    "        )\n",
    "        return img\n",
    "\n",
    "    def discriminator_forward(self, img):\n",
    "        logits = model.discriminator(img)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GAN()\n",
    "model.to(DEVICE)\n",
    "\n",
    "generator_optimizer = torch.optim.Adam(\n",
    "    model.generator.parameters(),\n",
    "    betas=(0.5, 0.999),\n",
    "    lr=GENERATOR_LEARNING_RATE\n",
    ")\n",
    "\n",
    "discriminator_optimizer = torch.optim.Adam(\n",
    "    model.discriminator.parameters(),\n",
    "    betas=(0.5, 0.999),\n",
    "    lr=DISCRIMINATOR_LEARNING_RATE\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('cs6073-dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "089acdbd81e861025207d6d06022757a580b22f8df3c6d0545687bfdaaf39b00"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
